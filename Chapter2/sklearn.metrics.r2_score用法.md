# $R^2$ 计算

# 是否拟合了足够的信息  

对于回归类算法而言，只探索数据预测是否准确是不足够的。除了数据本身的数值大小之外，我们还希望我们的模型能够捕捉到数据的”规律“，比如数据的分布规律，单调性等等，而是否捕获了这些信息并无法使用MSE来衡量  。

<center>
    <img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200113171026.png"/>
</center>

来看这张图，其中红色线是我们的真实标签，而蓝色线是我们的拟合模型。这是一种比较极端，但的确可能发生的情况。这张图像上，前半部分的拟合非常成功，看上去我们的真实标签和我们的预测结果几乎重合，但后半部分的拟合却非常糟糕，模型向着与真实标签完全相反的方向去了。对于这样的一个拟合模型，如果我们使用MSE来对它进行判断，它的MSE会很小，因为大部分样本其实都被完美拟合了，少数样本的真实值和预测值的巨大差异在被均分到每个样本上之后，MSE就会很小。但这样的拟合结果必然不是一个好结果，因为一旦我的新样本是处于拟合曲线的后半段的，我的预测结果必然会有巨大的偏差，而这不是我们希望看到的。所以，我们希望找到新的指标，除了判断预测的数值是否正确之外，还能够判断我们的模型是否拟合了足够多的，数值之外的信息  

降维算法PCA，使用方差来衡量数据上的信息量。如果方差越大，代表数据上的信息量越多，而这个信息量不仅包括了数值的大小，还包括了我们希望模型捕捉的那些规律。为了衡量模型对数据上的信息量的捕捉，我们定义了 $$R^2$$  来帮助我们：  

<center>
    <img src="https://raw.githubusercontent.com/HG1227/image/master/img_tuchuang/20200113171325.png"/>
</center>



其中 $$y$$ 是我们的真实标签，$$\hat y$$ 是我们的预测结果, $$\bar y$$ 是我们的均值，$$y - \bar y$$ 如果除以样本量m就是我们的方差。方差的本质是任意一个 $$y$$ 值和样本均值的差异，差异越大，这些值所带的信息越多。在 $$R^2$$ 中，分子是真实值和预测值之差的差值，也就是我们的模型没有捕获到的信息总量 , 分母是真实标签所带的信息量，所以其衡量的是$$1 -$$我们的模型没有捕获到的信息量占真实标签中所带的信息量的比例 , 所以， $$R^2$$ 越接近 1 越好。



$$R^2$$可以使用三种方式来调用，一种是直接从metrics中导入r2_score，输入预测值和真实值后打分。第二种是直接从线性回归LinearRegression的接口score来进行调用。第三种是在交叉验证中，输入"r2"来调用  

````python
metrics.r2_score(y_true, 
                 y_pred, 
                 sample_weight=None, 
                 multioutput='uniform_average'
                )
````

```python

from sklearn.metrics import r2_score
 
y_true = [1,2,4]
y_pred = [1.3,2.5,3.7]
r2_score(y_true,y_pred)
```

